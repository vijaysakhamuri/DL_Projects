{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification with Convolutional Neural Networks, CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Make the notebook compatible with both Python 2 and 3\n",
    "\n",
    "http://python-future.org/compatible_idioms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Plot graphs inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "1.13.1\n",
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Download the CIFAR-10 dataset\n",
    "\n",
    "More information on the dataset can be found here: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "The file is 17MB so this might take a while\n",
    "\n",
    "The dataset is broken into batches to prevent your machine from running out of memory. The CIFAR-10 dataset consists of 5 batches, named data_batch_1, data_batch_2, etc.. Each batch contains the labels and images that are one of the following:\n",
    "\n",
    "* 0 - airplane\n",
    "* 1 - automobile\n",
    "* 2 - bird\n",
    "* 3 - cat\n",
    "* 4 - deer\n",
    "* 5 - dog\n",
    "* 6 - frog\n",
    "* 7 - horse\n",
    "* 8 - ship\n",
    "* 9 - truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cifar-10/cifar-10-python.tar.gz',\n",
       " <httplib.HTTPMessage instance at 0x10ccb5cf8>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from six.moves import urllib\n",
    "\n",
    "CIFAR_10_FILE_NAME = 'cifar-10/cifar-10-python.tar.gz'\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "    CIFAR_10_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untar and unzip the files\n",
    "\n",
    "* The extracted files (one for each batch) are placed in the folder *cifar-10-batches-py/* under your current working directory \n",
    "* Each file is named *data_batch_1, data_batch_2* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open('cifar-10/cifar-10-python.tar.gz') as tar:\n",
    "    tar.extractall()\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and pre-process files\n",
    "\n",
    "* Access the image and the labels from a single batch specified by id (1-5)\n",
    "* Reshape the images, the images are **fed to the convolutional layer as a 4-D tensor**, notice that the reshape has the channels at axis index 1 \n",
    "* Transpose the axes of the reshaped image to be in this form: *[batch_size, height, width, channels]*, **channels should be the last axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "CIFAR10_DATASET_FOLDER = \"cifar-10-batches-py\"\n",
    "\n",
    "def load_cifar10_batch(batch_id):\n",
    "    with open(CIFAR10_DATASET_FOLDER + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        batch = pickle.load(file)\n",
    "\n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "features, labels = load_cifar10_batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Helper functions to display images as well as labels\n",
    "\n",
    "* Map the integer labels to the actual labels for display\n",
    "* Plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lookup = ['airplane', \n",
    "          'automobile', \n",
    "          'bird', \n",
    "          'cat', \n",
    "          'deer', \n",
    "          'dog', \n",
    "          'frog', \n",
    "          'horse', \n",
    "          'ship', \n",
    "          'truck']\n",
    "\n",
    "def display_feature_label(features, labels, index):\n",
    "    if index >= len(features):\n",
    "        raise Error(\"index out of range\")\n",
    "        \n",
    "    print(\"Label: \", lookup[labels[index]])\n",
    "    plt.imshow(features[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  horse\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1192a6b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_feature_label(features, labels, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Access the *training* data and the corresponding labels\n",
    "\n",
    "Each batch in the CIFAR-10 dataset has randomly picked images, so the images come pre-shuffled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images:  8000\n",
      "Training labels:  8000\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(features) * 0.8)\n",
    "\n",
    "training_images = features[:train_size,:,:]\n",
    "\n",
    "training_labels = labels[:train_size]\n",
    "\n",
    "print(\"Training images: \", len(training_images))\n",
    "print(\"Training labels: \", len(training_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Access the *test* data and the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images:  2000\n",
      "Test labels:  2000\n"
     ]
    }
   ],
   "source": [
    "test_images = features[train_size:,:,:]\n",
    "\n",
    "test_labels = labels[train_size:]\n",
    "\n",
    "print(\"Test images: \", len(test_images))\n",
    "print(\"Test labels: \", len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The CIFAR-10 dataset has color images\n",
    "\n",
    "* Each image is of size 32x32\n",
    "* The image is RGB so has 3 channels, and requires 3 numbers to represent each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "n_inputs = height * width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Placeholders for training data and labels\n",
    "\n",
    "* The training dataset placeholder can have any number of instances and each instance is an array of 32x32 pixels (we've already reshaped the data earlier)\n",
    "* The images are fed to the convolutional layer as a 4D tensor *[batch_size, height, width, channels]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,  height, width, channels], name=\"X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a dropout layer to avoid overfitting the training data\n",
    "\n",
    "* The training flag is set to False during prediction and is True while training (dropout is applied only in the training phase)\n",
    "* The dropout_rate indicates the chances that a neuron is turned off during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dropout_rate = 0.3\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32, shape=[None], name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network design\n",
    "\n",
    "* 2 convolutional layers\n",
    "* 1 max pooling layer\n",
    "* 1 convolutional layer\n",
    "* 1 max pooling layer\n",
    "* 2 fully connected layers\n",
    "* Output logits layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(X_drop, filters=32,\n",
    "                         kernel_size=3,\n",
    "                         strides=1, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conv2 = tf.layers.conv2d(conv1, filters=64, \n",
    "                         kernel_size=3,\n",
    "                         strides=2, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling reduces the size of the image\n",
    "\n",
    "The pooled image is only 1/4th the size of the original image with this kernel size and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pool3 = tf.nn.max_pool(conv2,\n",
    "                       ksize=[1, 2, 2, 1],\n",
    "                       strides=[1, 2, 2, 1],\n",
    "                       padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conv4 = tf.layers.conv2d(pool3, filters=128, \n",
    "                         kernel_size=4,\n",
    "                         strides=3, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the pooled layer to be a 1-D vector (flatten it) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pool5 = tf.nn.max_pool(conv4,\n",
    "                       ksize=[1, 2, 2, 1],\n",
    "                       strides=[1, 1, 1, 1],\n",
    "                       padding=\"VALID\")\n",
    "\n",
    "pool5_flat = tf.reshape(pool5, shape=[-1, 128 * 2 * 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fullyconn1 = tf.layers.dense(pool5_flat, 128,\n",
    "                             activation=tf.nn.relu, name=\"fc1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fullyconn2 = tf.layers.dense(fullyconn1, 64,\n",
    "                             activation=tf.nn.relu, name=\"fc2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 10 possible classifications in the CIFAR-10 dataset\n",
    "\n",
    "The number of outputs of the logits layer should be 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(fullyconn2, 10, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final output layer with softmax activation\n",
    "\n",
    "The *tf.nn.sparse_softmax_cross_entropy_with_logits* will apply the softmax activation as well as calculate the cross-entropy as our cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                          labels=y)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correctness and accuracy of the prediction\n",
    "\n",
    "* Check whether the highest probability output in logits is equal to the y-label\n",
    "* Check the accuracy across all predictions (How many predictions did we get right?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a helper method to access training data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_next_batch(features, labels, train_size, batch_index, batch_size):\n",
    "    training_images = features[:train_size,:,:]\n",
    "    training_labels = labels[:train_size]\n",
    "    \n",
    "    test_images = features[train_size:,:,:]\n",
    "    test_labels = labels[train_size:]\n",
    "    \n",
    "    start_index = batch_index * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "\n",
    "    return features[start_index:end_index,:,:], labels[start_index:end_index], test_images, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model\n",
    "\n",
    "* For smaller training data you'll find that the model performs poorly, it improves as you increase the size of the training data (use all batches)\n",
    "* Ensure that dropout is enabled during training to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.1875 Test accuracy: 0.2405\n",
      "1 Train accuracy: 0.289062 Test accuracy: 0.338\n",
      "2 Train accuracy: 0.335938 Test accuracy: 0.373\n",
      "3 Train accuracy: 0.40625 Test accuracy: 0.3805\n",
      "4 Train accuracy: 0.429688 Test accuracy: 0.412\n",
      "5 Train accuracy: 0.46875 Test accuracy: 0.432\n",
      "6 Train accuracy: 0.476562 Test accuracy: 0.4615\n",
      "7 Train accuracy: 0.539062 Test accuracy: 0.5035\n",
      "8 Train accuracy: 0.507812 Test accuracy: 0.509\n",
      "9 Train accuracy: 0.53125 Test accuracy: 0.5135\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "#         batch_index = 0\n",
    "        # Add this in when we want to run the training on all batches in CIFAR-10\n",
    "        for batch_id in range(1, 6):\n",
    "            batch_index = 0\n",
    "            \n",
    "            features, labels = load_cifar10_batch(batch_id)\n",
    "            train_size = int(len(features) * 0.8)\n",
    "            \n",
    "            for iteration in range(train_size // batch_size):\n",
    "                X_batch, y_batch, test_images, test_labels = get_next_batch(features, \n",
    "                                                                            labels, \n",
    "                                                                            train_size, \n",
    "                                                                            batch_index,\n",
    "                                                                            batch_size)\n",
    "                batch_index += 1\n",
    "\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: test_images, y: test_labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "        save_path = saver.save(sess, \"./my_mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
